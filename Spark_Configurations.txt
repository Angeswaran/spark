Common:-
=========
spark.executor.instances
spark.yarn.executor.memoryOverhead
spark.executor.memory
spark.yarn.driver.memoryOverhead
spark.driver.memory
spark.executor.cores
spark.driver.cores
spark.default.parallelism

Spark-Submit Configurations:-
=============================
--conf spark.serializer=org.apache.spark.serializer.KyroSerializer
spark.dynamicAllocation.initialExecutors=100
spark.dynamicAllocation.minExecutors=100
spark.dynamicAllocation.maxExecutors=500
spark.sql.cbo.enabled=true
spark.scaas.log.level=job
spark.yarn.maxAppAttempts=2
spark.executor.heartbeatInterval=30s
spark.dynamicAllocation.executorIdleTimeout=120s
spark.speculation=true
spark.speculation.interval=100ms
spark.speculation.multipliers=1.5
spark.speculation.quantile=0.75
spark.sql.broadcastTimeout=48000 --> Timeout in seconds for the broadcast wait time in broadcast joins
spark.yarn.max.executor.failures=100
spark.yarn.am.memoryOverhead=5120
spart.driver.maxResultSize=10g
spark.memory.fraction=0.6
spark.memory.storageFraction=0.5
spark.default.parellelism=200
spark.sql.shufffle.partition=2500
spark.netweork.timeout=2400s
spark.shuffle.io.retryWait=600s
spark.rpc.askTimeout=2400s

Declaring Spark Properties:-
==========================

spark = SparkSession.builder.enableHiveSupport().getorCreate()
spark.conf.set("hive.exec.dynamic.partition","true")
spark.conf.set("hive.exec.dynamci.partition.mode","nonstrict")
spark.conf.set("spark.shuffle.compress","true")
spark.conf.set("spark.debug.maxToStringFields",'2000')
spark.conf.set("optimize.sort.dynamic.partitioning","true")
spark.conf.set("spark.sql.hive.convertmetastoreParquest","true")
spark.conf.set("spark.debug.maxToStringFields",'100')
spark.conf.set("spark.sql.parquet.writeLegacyFormat","true")
spark.conf.set("hive.enforce.bucketing',"true")
spark.conf.set("hive.enforce.sorting","true")

spark.conf.set("spark.sql.cbo.enabled","true")
spark.conf.set("spark.scass.log.level","job")
spark.conf.set("spark.yarn.maxAttempts",'2")
spark.conf.set("spark.executor.heartbeatInterval","30s")
spark.conf.set("spark.dynamicAllocation.executorIdleTimeout","180")
spark.conf.set("spark.dynamicAllocation.initialExecutors","50")
spark.conf.set("spark.dynamicAllocation.minExecutors","50")
spark.conf.set("spark.dynamicAllocation.maxExecutors","300")
spark.conf.set("spark.speculation","true")
spark.conf.set("spark.speculation.interval","100ms")
spark.conf.set("spark.speculation.multiplier","1.5")
spark.conf.set("spark.speculation.quantile","0.75")
spark.conf.set("spark.sql.broadcastTimeout","48000")
spark.conf.set("spark.yarn.max.executor.failures","100")
spark.conf.set("spark.yarn.am.memoryOverhead","5120")
cpark.conf.set("spark.driver.maxResultSize","10")
spark.conf.set("spark.memory.fraction","0.6")
spark.conf.set("spark.memory.storageFraction","0.5")
spark.conf.set("spark.default.parellelism",'2000")
spark.conf.set("spark.sql.shuffle.partitions","2000")
spark.conf.set("spark.netwok.timeout""2400s")
spark.conf.set("spark.shuffle.io.retryWait","600s")
spark.conf.set("spark.rpc.askTimeout","5400s")





