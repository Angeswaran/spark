from pyspark import *
import sys
from datetime import datetime
def main(file):
	x = sc._jsc.hadoopConfiguration()
	x.set("hadoop.security.credential.provider.path", file)
	a = x.getPassword("fs.s3a.access.key")
	access_key = ""
	for i in range(a.__len__()):
		access_key = access_key + str(a.__getitem__(i))
	#print("ACCESS_KEY:"+access_key)
	b = x.getPassword("fs.s3a.secret.key")
	secret_key = ""
	for i in range(b.__len__()):
		secret_key = secret_key + str(b.__getitem__(i))
	#print("SECRET_KEY:"+secret_key)
	return access_key,secret_key
	
if __name__ == '__main__':
	conf = SparkConf().setAppName("aws_jceks_file")
	sc = SparkContext(conf=conf)
	jceks_file=sys.argv[1]
	print(main(jceks_file))
